{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "from ml import PINN\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a, b):\n",
    "   return a*2 if a > b else 0 if a == b else a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(1,3, size=(10000, 3))\n",
    "b = np.random.randint(1,3, size=(10000, 3))\n",
    "d = np.vectorize(f)\n",
    "c = torch.from_numpy(d(a,b)).float()\n",
    "a = torch.from_numpy(np.stack((a,b),1)).float()\n",
    "\n",
    "a = a.reshape(1000,2,10,3)\n",
    "c = c.reshape(1000,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PINN(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.239779085755348\n",
      "2.877691105365753\n",
      "2.8337678079605104\n",
      "2.83963842189312\n",
      "16.722772500634193\n",
      "2.823097601056099\n",
      "2.7901536296606064\n",
      "2.813803819894791\n",
      "2.825577950000763\n",
      "2.8372088977098464\n",
      "2.8447902873754503\n",
      "2.846252118945122\n",
      "2.848776544570923\n",
      "2.855767375469208\n",
      "3.2125203330516814\n",
      "2.8696457419395447\n",
      "2.867240918517113\n",
      "2.8540467336177824\n",
      "2.873078009366989\n",
      "2.8458044003248215\n",
      "2.8508386569023134\n",
      "4.21164910697937\n",
      "2.8358504868745804\n",
      "2.8415123492479326\n",
      "2.847861073374748\n",
      "2.8420212256908415\n",
      "2.8562850716114045\n",
      "2.967610092282295\n",
      "2.8362008279561994\n",
      "2.839254947066307\n",
      "2.83459405708313\n",
      "5.148824778497219\n",
      "2.840136612892151\n",
      "2.8444275082349777\n",
      "2.846236804842949\n",
      "2.851368021965027\n",
      "2.842660846233368\n",
      "2.90622881436348\n",
      "2.8558128646612166\n",
      "4.0671891021728515\n",
      "2.8657167612314223\n",
      "2.8545537325143813\n",
      "2.845867545843124\n",
      "2.860161954164505\n",
      "2.940207561850548\n",
      "2.868827844142914\n",
      "2.8540434739589693\n",
      "2.8439073988199235\n",
      "2.8494759558439253\n",
      "2.828406408190727\n",
      "5.139924596190452\n",
      "2.8170305118560792\n",
      "2.832822778224945\n",
      "2.8448403791189194\n",
      "2.8490528223514557\n",
      "2.8462005589008332\n",
      "2.8547935806512834\n",
      "2.8485488723516466\n",
      "14.341188799262047\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m qq \u001b[39m=\u001b[39m c[i]\n\u001b[1;32m     10\u001b[0m output \u001b[39m=\u001b[39m loss(res, c[i])\n\u001b[0;32m---> 11\u001b[0m output\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     12\u001b[0m optim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m ls\u001b[39m+\u001b[39m\u001b[39m=\u001b[39moutput\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/bio_sensors/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/bio_sensors/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "for l in range(300):\n",
    "    ls = 0\n",
    "    for i,j in enumerate(a):\n",
    "        optim.zero_grad()\n",
    "        res = net(j).squeeze()\n",
    "        qq = c[i]\n",
    "        output = loss(res, c[i])\n",
    "        output.backward()\n",
    "        optim.step()\n",
    "        ls+=output.item()\n",
    "    print(ls/len(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net(a[10]).squeeze())\n",
    "print(c[10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_sensors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
